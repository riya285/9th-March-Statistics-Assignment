{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ef32fd-6d05-49fb-8481-1ab907aafda4",
   "metadata": {},
   "source": [
    "Q1: Probability Mass Function (PMF) and Probability Density Function (PDF)\n",
    "\n",
    "Probability Mass Function (PMF) is a function that gives the probability of each possible outcome in a discrete random variable. It maps the values of the random variable to their associated probabilities. For example, consider a fair six-sided die roll. The PMF of this random variable would assign a probability of 1/6 to each of the possible outcomes (1, 2, 3, 4, 5, and 6).\n",
    "\n",
    "Probability Density Function (PDF) is a function that describes the likelihood of continuous random variables taking on specific values within a given range. Unlike the PMF, which deals with discrete variables, the PDF deals with continuous variables. For example, in the case of a continuous distribution like the standard normal distribution, the PDF specifies the probability density at each possible value of the variable.\n",
    "\n",
    "Q2: Cumulative Density Function (CDF)\n",
    "\n",
    "The Cumulative Density Function (CDF) of a random variable gives the probability that the variable takes on a value less than or equal to a specified value. It essentially accumulates the probabilities as you move along the range of possible values of the variable. The CDF is used to understand the distribution's behavior and calculate probabilities of specific events. For example, in a normal distribution, the CDF tells you the probability of a random variable being less than a particular value.\n",
    "\n",
    "Q3: Normal Distribution and its Parameters\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution, is a symmetric bell-shaped probability distribution. It's widely used to model real-world phenomena due to its ubiquity in nature and the Central Limit Theorem (which I'll explain in a later question). The normal distribution is fully defined by two parameters: the mean (μ) and the standard deviation (σ). The mean controls the center of the distribution, while the standard deviation controls the spread or width.\n",
    "\n",
    "Examples of situations where the normal distribution might be used:\n",
    "\n",
    "Heights of people in a population.\n",
    "Measurement errors in scientific experiments.\n",
    "IQ scores in a population.\n",
    "Many financial metrics like stock prices.\n",
    "The shape of the distribution is influenced by these parameters:\n",
    "\n",
    "If you increase the mean, the distribution shifts to the right.\n",
    "If you increase the standard deviation, the distribution becomes wider and flatter.\n",
    "Q4: Importance of Normal Distribution and Real-life Examples\n",
    "\n",
    "The normal distribution is important because of its prevalence in various natural and human-made processes. Many statistical techniques are based on the assumption of normality. Some real-life examples of normal distribution include:\n",
    "\n",
    "Human height: Most people fall around the average height, with fewer individuals being extremely tall or short.\n",
    "Exam scores: In large populations, scores on well-designed exams often follow a normal distribution.\n",
    "Random measurement errors: Errors in scientific measurements tend to cluster around the true value in a symmetric pattern.\n",
    "\n",
    "Q5: Bernoulli Distribution, Binomial Distribution\n",
    "\n",
    "Bernoulli Distribution models a single binary outcome (success or failure) with a probability of success denoted as 'p'. For example, flipping a coin can be modeled using a Bernoulli distribution, where 'p' is the probability of getting heads.\n",
    "\n",
    "Binomial Distribution extends the Bernoulli distribution to model the number of successes in a fixed number of independent Bernoulli trials. It has two parameters: 'n' (number of trials) and 'p' (probability of success in each trial). For example, the number of heads in 10 coin flips would follow a binomial distribution.\n",
    "\n",
    "The key difference: Bernoulli is for a single trial, while binomial is for multiple trials.\n",
    "\n",
    "Q6: Probability Calculation for Normal Distribution\n",
    "\n",
    "For a normally distributed dataset with a mean (μ) of 50 and a standard deviation (σ) of 10, to find the probability that a randomly selected observation will be greater than 60:\n",
    "\n",
    "Calculate the z-score:\n",
    "z = (X - μ) / σ\n",
    "z = (60 - 50) / 10\n",
    "z = 1\n",
    "\n",
    "Use the standard normal distribution table or calculator to find the cumulative probability for z = 1.\n",
    "P(Z > 1) ≈ 0.1587\n",
    "\n",
    "So, the probability that a randomly selected observation will be greater than 60 is approximately 0.1587.\n",
    "\n",
    "Q7: Uniform Distribution\n",
    "\n",
    "A uniform distribution, also known as a rectangular distribution, is a probability distribution in which all outcomes have equal probability. It's characterized by a constant probability density function within a specific range.\n",
    "\n",
    "Example: Consider rolling a fair six-sided die. Each face has an equal probability of 1/6, and thus, the distribution is uniform.\n",
    "\n",
    "Q8: Z-Score and its Importance\n",
    "\n",
    "The z-score measures how many standard deviations a data point is away from the mean in a normal distribution. It's calculated as (X - μ) / σ, where X is the data point, μ is the mean, and σ is the standard deviation. The z-score allows us to standardize data and compare it across different distributions. It's important because it helps us understand the relative position of a data point within the distribution and assess its rarity or significance.\n",
    "\n",
    "Q9: Central Limit Theorem (CLT)\n",
    "\n",
    "The Central Limit Theorem states that when independent random variables are added, their sum tends to follow a normal distribution, regardless of the original distribution of the variables. This is especially true when the sample size is large. The CLT is significant because it allows us to make inferences about a population's mean using the sample mean, even when the population's distribution is unknown.\n",
    "\n",
    "Q10: Assumptions of the Central Limit Theorem\n",
    "\n",
    "The Central Limit Theorem holds under certain assumptions:\n",
    "\n",
    "Independence: The random variables should be independent of each other.\n",
    "Sample Size: The larger the sample size, the better the normal approximation.\n",
    "Finite Variance: The random variables should have finite variances.\n",
    "These assumptions ensure that the sampling distribution of the sample mean approaches a normal distribution, even if the original population distribution is not normal.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
